# Reconocimiento-facial
Resumen de la red. Reutilizando la red para clasificar perros y gatos, se le cambiaron la cantidad de clases de 2 a 40 (que es el número total de atributos). También se modificó el tamaño de las imágenes para que coincidiera con el tamaño de las fotos de rostros de la base de datos de CelebA.
Problemas: El primer problema que tuve fue que después de terminar el tiempo estimado de entrenamiento de una época, se quedaba mucho rato haciendo algo. Al principio creí que era algo anormal, hasta que vi que cuando se trabaja con bases de datos tan grandes, solamente se toma un estimado de cuánto tiempo le va a tomar a la computadora analizar las imágenes de training, después de eso, se toma tiempo para procesar las imágenes utilizadas para validar. Por tanto, eso era normal. Quité el hecho de que se estuvieran barajando las imágenes en cada época, aunque dudo si fue beneficioso o no para evitar el sobre ajuste. 

Entrené por 20 épocas en varias ocasiones. Para lograrlo, lo hacía siempre de 4 en 4 épocas. Cuando terminaba el entrenamiento, en el código para ejecutar la red había un comando para guardarla en un archivo .h5. Posteriormente en otro documento cargaba ese archivo en donde ya había entrenado algunos pesos y volvía a entrenar, así no perdía nada del progreso que pudiera tener al entrenar, incluso era beneficioso porque cuando notaba que la función de costo no disminuía, podía cambiar el valor del learning rate y así lograba que la función de costo bajara un poco más. Dejé de entrenar cuando el porcentaje de accuracy en validación no solo no aumentaba, sino que disminuía drásticamente. Para época llevaba al rededor de 5000 pasos, por tanto, se tardaba en cada época aproximadamente 15 minutos más el tiempo de validación, el cual no estaba incluido.

La última versión de la red está en el archivo red3.h5

Me quedé en la parte en la que tenía que añadir un nuevo clasificador. Los problemas que tuve fueron cómo congelar ciertos parámetros de la red para hacer que ya no entrenaran y que solamente se entrenada la última capa de red densa con 2 neuronas. Hice intentos de cómo usar image data generator en keras, sin embargo, la sintaxis de la función no me permitía utilizar los tensores que ya tenía preparados previamente, lo cual se me hizo confuso. También intenté hacer una prueba de evaluación de la red, pues quería ver qué tanto acertaba en las características de las personas, sin embargo, tuve el mismo problema. Este último intento quedó registrado en el documento llamado Prueba_de_evaluación.py, el cual es un intento fallido.

Al 14 de noviembre, no he logrado terminar el proyecto, sin embargo, reporto mis avances hasta ahora.

# ACTUALIZACIÓN 25 DE NOVIEMBRE, 2022.
En el archivo llamado "aumentando_datos_clasificación_binaria" tomé fotos mías (específicamente 21) para hacerles transformaciones como pequeñas rotaciones, reflexiones, zoom, estirarlas verticalmente u horizontalmente. Los espacios que quedaban vacíos al rotar o estirar los llenaba con los colores que estaban cerca de los alrededores vacíos. Con ello, transformé las 21 fotografías de mi rostro en 6642 fotografías. Intenté hacer el problema de clasificación binaria como se había hecho en el código para distinguir entre perros y gatos (esto quedó escrito en el archivo llamado "clasificación binaria"). Sin embargo, al querer utilizar las capas del modelo de extracción de características que había entrenado con la base de datos CelebA, tuve problemas. Pienso que esto viene porque en lugar de haberlo hecho exactamente igual al problema de perros y gatos, en donde distinguía ambas fotos por la carpeta en donde se encontraba, debí haber hecho también los datasets para alimentarlo a las capas que precisamente entrené con datasets también. Este fue un intento fallido.
