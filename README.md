# Reconocimiento-facial
Resumen de la red. Reutilizando la red para clasificar perros y gatos, se le cambiaron la cantidad de clases de 2 a 40 (que es el número total de atributos). También se modificó el tamaño de las imágenes para que coincidiera con el tamaño de las fotos de rostros de la base de datos de CelebA.
Problemas: El primer problema que tuve fue que después de terminar el tiempo estimado de entrenamiento de una época, se quedaba mucho rato haciendo algo. Al principio creí que era algo anormal, hasta que vi que cuando se trabaja con bases de datos tan grandes, solamente se toma un estimado de cuánto tiempo le va a tomar a la computadora analizar las imágenes de training, después de eso, se toma tiempo para procesar las imágenes utilizadas para validar. Por tanto, eso era normal. Quité el hecho de que se estuvieran barajando las imágenes en cada época, aunque dudo si fue beneficioso o no para evitar el sobre ajuste. 

Entrené por 20 épocas en varias ocasiones. Para lograrlo, lo hacía siempre de 4 en 4 épocas. Cuando terminaba el entrenamiento, en el código para ejecutar la red había un comando para guardarla en un archivo .h5. Posteriormente en otro documento cargaba ese archivo en donde ya había entrenado algunos pesos y volvía a entrenar, así no perdía nada del progreso que pudiera tener al entrenar, incluso era beneficioso porque cuando notaba que la función de costo no disminuía, podía cambiar el valor del learning rate y así lograba que la función de costo bajara un poco más. Dejé de entrenar cuando el porcentaje de accuracy en validación no solo no aumentaba, sino que disminuía drásticamente. Para época llevaba al rededor de 5000 pasos, por tanto, se tardaba en cada época aproximadamente 15 minutos más el tiempo de validación, el cual no estaba incluido.

La última versión de la red está en el archivo red3.h5

Me quedé en la parte en la que tenía que añadir un nuevo clasificador. Los problemas que tuve fueron cómo congelar ciertos parámetros de la red para hacer que ya no entrenaran y que solamente se entrenada la última capa de red densa con 2 neuronas. Hice intentos de cómo usar image data generator en keras, sin embargo, la sintaxis de la función no me permitía utilizar los tensores que ya tenía preparados previamente, lo cual se me hizo confuso. También intenté hacer una prueba de evaluación de la red, pues quería ver qué tanto acertaba en las características de las personas, sin embargo, tuve el mismo problema. Este último intento quedó registrado en el documento llamado Prueba_de_evaluación.py, el cual es un intento fallido.

Al 14 de noviembre, no he logrado terminar el proyecto, sin embargo, reporto mis avances hasta ahora.

# PRIMERA ACTUALIZACIÓN 25 DE NOVIEMBRE, 2022.
En el archivo llamado "aumentando_datos_clasificación_binaria" tomé fotos mías (específicamente 21) para hacerles transformaciones como pequeñas rotaciones, reflexiones, zoom, estirarlas verticalmente u horizontalmente. Los espacios que quedaban vacíos al rotar o estirar los llenaba con los colores que estaban cerca de los alrededores vacíos. Con ello, transformé las 21 fotografías de mi rostro en 6642 fotografías. Intenté hacer el problema de clasificación binaria como se había hecho en el código para distinguir entre perros y gatos (esto quedó escrito en el archivo llamado "clasificación binaria"). Sin embargo, al querer utilizar las capas del modelo de extracción de características que había entrenado con la base de datos CelebA, tuve problemas. Pienso que esto viene porque en lugar de haberlo hecho exactamente igual al problema de perros y gatos, en donde distinguía ambas fotos por la carpeta en donde se encontraba, debí haber hecho también los datasets para alimentarlo a las capas que precisamente entrené con datasets también. Este fue un intento fallido.

# SEGUNDA ACTUALIZACIÓN 25 DE NOVIEMBRE, 2022.
Decidí no utilizar la estructura de la red de perros y gatos, pues la forma de los arreglos de numpy en los que se organizaban los datos de entrenamiento y validación no coincidían con la forma del tensor que le alimenté a la red neuronal que extraía características de los rostros (entrenada con la base de datos CelebA). En lugar de eso, construí dos datasets básicos. Uno con 5000 imágenes de la base de datos CelebA, y otra con 6642 fotos de mi rostro. En sus características, en la columna de características de los datasets, al que no tenía mi rostro le puse una columna de ceros y al que tenía mi rostro una columna de 1. Posteriormente concatené ambos datasets para tener uno único, este último datasets tenía una longitud de la suma de los dos datasets que uní (lo que me indicaba que estaba bien la operación realizada). Después reutilicé código del script cargar_atributos, en donde tenía una función que revolvía los elementos en el dataset y los separaba en 3, uno de training, otro de test y otro de validación. Agregué una por una las capas del modelo pre-entrenado hasta que empezaro las capas densas de dicho modelo. A partir de ahí, agregué una capa densa de una neurona. Congelé los pesos de las capas que ya habían sido entrenadas y al compilar el modelo no hubo ningún inconveniente, pues ya los datasets tenían la dimensión adecuada.
Al haber entrenado con pocas imágenes, vi que subió mucho la precisión... Pienso que la red tendría un mejor desempeño si aumento las imágenes de mi rostro que tengo guardadas en memoria. 
